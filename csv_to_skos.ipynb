{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import re\n",
    "from rdflib import Namespace, Graph, Literal, URIRef, RDF, SKOS, DCTERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_path = Path.cwd() / \"data\" / \"csv\" / \"schlagworte.csv\"\n",
    "\n",
    "\n",
    "def open_csv(csv_path) -> list:\n",
    "    csv_data = []\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\"|\")\n",
    "        for row in reader:\n",
    "            csv_data.append(row)\n",
    "    return csv_data\n",
    "\n",
    "# Schlagwort: Definierter Begriff, kann aus einem oder mehreren WÃ¶rtern bestehen, kann Deskriptor oder Nicht-Desckriptor sein\n",
    "# Art: DS = Deskriptor, ND = Nicht-Deskriptor, (Verweis mit s. im Feld \"Text\"), D = Deskriptor mit Verweis im Feld \"Text\"\n",
    "# Feldbegr: Feldbegriff, Kategorisierung der Deskriptoren\n",
    "# Text: Definition des Deskriptors oder Querverweis mit \"s.\" und \"s.a.\"\n",
    "\n",
    "\n",
    "def findAllNodes(data):\n",
    "    root = []\n",
    "    for item in data:\n",
    "        if item[\"ART\"] == \"DS\":\n",
    "            # item is main node append it\n",
    "            if item[\"FELDBEGR\"] == \"\":\n",
    "                continue\n",
    "            node = {\n",
    "                \"schlagwort\": item[\"SCHLAGWORT\"],\n",
    "                \"dokument-id\": item[\"DOKUMENT-ID\"],\n",
    "                \"text\": item[\"TEXT\"],\n",
    "                \"discipline\": item[\"FELDBEGR\"]\n",
    "            }\n",
    "            root.append(node)\n",
    "    return root\n",
    "\n",
    "csv_data = open_csv(csv_path)\n",
    "root = findAllNodes(csv_data)\n",
    "disciplines = set([node['discipline'] for node in root])\n",
    "\n",
    "print(f\"Distict disciplines: {*disciplines,}\")\n",
    "print(f\"Number of distinct disciplines: {len(disciplines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Append all all Nodes to their respective discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseTree(item, data) -> dict:\n",
    "    \"\"\"\n",
    "    gets an item as input and looks for descriptors in data till it finds a \"DS\"-descriptor\n",
    "    \"\"\"\n",
    "    # split after s. or s.a. in TEXT column\n",
    "    descriptor_split = re.compile(r\"s\\.a\\.|s\\.\")\n",
    "    \n",
    "    # look for the descriptor in data\n",
    "    def findDescriptor(item, data):\n",
    "        # find the descriptor\n",
    "        descriptor = re.split(descriptor_split, item[\"TEXT\"])[-1].strip()\n",
    "        \n",
    "        descriptor_nodes = [node for node in data if node[\"SCHLAGWORT\"].strip() == descriptor]\n",
    "        if len(descriptor_nodes) == 0:\n",
    "            ## use the more insensitive method to check if the string appears in another string\n",
    "            descriptor_nodes = [node for node in data if descriptor in node[\"SCHLAGWORT\"].strip()]\n",
    "\n",
    "        try:\n",
    "            target_node = next(node for node in descriptor_nodes if node[\"ART\"] == \"DS\")\n",
    "            if target_node:\n",
    "                return target_node\n",
    "            else:\n",
    "                for node in descriptor_nodes:\n",
    "                    findDescriptor(target_node, data)\n",
    "\n",
    "        except:\n",
    "            print(f\"item :{item}\")\n",
    "            print(f\"descriptor: {descriptor}\")\n",
    "            print(f\"target_node:  {target_nodes}\")\n",
    "\n",
    "\n",
    "    ds_node = findDescriptor(item, data)\n",
    "    return ds_node\n",
    "    \n",
    "\n",
    "def buildListOfDisciplines(data) -> list:\n",
    "    discipline_list = []\n",
    "    for item in data:\n",
    "        # second iteration when all mein node exists\n",
    "        # if item is a Non-Deskriptor find its Deskriptor (DS) and append it to DS as hiddenLabel\n",
    "\n",
    "        if item[\"ART\"].strip() == \"DS\":\n",
    "            discipline = item[\"FELDBEGR\"]\n",
    "            if discipline == \"\":\n",
    "                continue\n",
    "\n",
    "            # if list empty, append the discipline\n",
    "            if len(discipline_list) == 0:\n",
    "                discipline_list.append({discipline: []})\n",
    "            # check if the discipline is already there, otherwise append\n",
    "            elif len([d for d in discipline_list if discipline in d.keys()]) == 0:\n",
    "                discipline_list.append({discipline: []})\n",
    "\n",
    "            item.update({\"discipline\": item.get(\"FELDBEGR\", \"\")})\n",
    "            \n",
    "            next(d[discipline] for d in discipline_list if discipline in d.keys()).append(item)\n",
    "\n",
    "        # node is not a descriptor\n",
    "        else:\n",
    "            # set node values\n",
    "            node = item\n",
    "\n",
    "            # find the parent_node it belongs to\n",
    "            parent_node = parseTree(item, data)\n",
    "\n",
    "            discipline = parent_node[\"FELDBEGR\"]\n",
    "\n",
    "            # append parent_node to node[\"broader\"]\n",
    "            node[\"broader\"] = parent_node[\"DOKUMENT-ID\"]\n",
    "\n",
    "            # if discipline not in list, append the discipline\n",
    "            if len(discipline_list) == 0:\n",
    "                discipline_list.append({discipline: []})\n",
    "            # check if the discipline is already there, otherwise append\n",
    "            elif len([d for d in discipline_list if discipline in d.keys()]) == 0:\n",
    "                discipline_list.append({discipline: []})\n",
    "\n",
    "            next(d[discipline] for d in discipline_list if discipline in d.keys()).append(node)\n",
    "\n",
    "    return discipline_list\n",
    "\n",
    "discipline_list = buildListOfDisciplines(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build csv files for each discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildCSV(data):\n",
    "    csv_out_path = Path.cwd() / \"data\" / \"csv_out\"\n",
    "    csv_out_path.mkdir(exist_ok=True, parents=True)\n",
    "    counter = 0\n",
    "\n",
    "    for d in data:\n",
    "        discipline = next(iter(d))\n",
    "        csv_path = Path(csv_out_path / (str(discipline) + \".csv\"))\n",
    "        csv_path.touch(exist_ok=True)\n",
    "        with open(Path(csv_out_path / (str(discipline) + \".csv\")), 'w', newline='') as csvfile:\n",
    "            fieldnames = ['DOKUMENT-ID', 'SCHLAGWORT', 'ART', 'TEXT', 'discipline', 'narrower', 'broader']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames,extrasaction='ignore')\n",
    "\n",
    "            writer.writeheader()\n",
    "\n",
    "            for i, item in enumerate(d[discipline]):\n",
    "\n",
    "                writer.writerow(item)\n",
    "                counter += 1\n",
    "            print(f\"{discipline} has {i} items\")\n",
    "    print(counter)\n",
    "buildCSV(discipline_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## build skos-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildGraph(data):\n",
    "    systematics_name = \"eaf-schlagwortverzeichnis-all\"\n",
    "    g = Graph()\n",
    "    namespace = Namespace(\"http://w3id.org/openeduhub/vocabs/\" + systematics_name + \"/\")\n",
    "    base_url = URIRef(namespace)\n",
    "\n",
    "    g.add(( base_url, RDF.type, SKOS.ConceptScheme))\n",
    "    g.add(( base_url, DCTERMS.title, Literal(systematics_name, lang=\"de\")))\n",
    "\n",
    "\n",
    "    for subject in data:\n",
    "        discipline = next(iter(subject))\n",
    "        # TODO for testing\n",
    "        if str(discipline) not in [\"Mathematik\", \"Physik\"]:\n",
    "            continue\n",
    "        print(discipline)\n",
    "        # END TODO\n",
    "\n",
    "        discipline_url = URIRef(namespace + str(discipline.lower().replace(\" \", \"-\")))\n",
    "        g.add( (discipline_url, RDF.type, SKOS.Concept) )\n",
    "        g.add( (discipline_url, SKOS.prefLabel, Literal(str(discipline), lang=\"de\" ) ) )\n",
    "\n",
    "        # add topConceptOf\n",
    "        g.add(( discipline_url, SKOS.topConceptOf, base_url) )\n",
    "        g.add(( base_url, SKOS.hasTopConcept, discipline_url) )\n",
    "\n",
    "        def addItem(item):\n",
    "            item_url = URIRef(namespace + item[\"DOKUMENT-ID\"])\n",
    "\n",
    "            g.add( (item_url, RDF.type, SKOS.Concept) )\n",
    "            g.add( (item_url, SKOS.prefLabel, Literal(item[\"SCHLAGWORT\"], lang=\"de\")) )\n",
    "            g.add( (item_url, SKOS.inScheme, base_url) )\n",
    "\n",
    "            if \"broader\" in item.keys():\n",
    "                child_url = URIRef(namespace + item[\"broader\"])\n",
    "                g.add( (item_url, SKOS.broader, child_url) )\n",
    "                g.add( (child_url, SKOS.narrower, item_url) )\n",
    "\n",
    "\n",
    "        for item in subject[discipline]:\n",
    "            item_url = URIRef(namespace + item[\"DOKUMENT-ID\"])\n",
    "\n",
    "            # if item is a descriptor, add it\n",
    "            if item[\"ART\"] == \"DS\":\n",
    "                # add item to discipline narrower\n",
    "                g.add((discipline_url, SKOS.narrower, item_url))\n",
    "                # and add discipline narrower to item broader\n",
    "                g.add((item_url, SKOS.broader, discipline_url))\n",
    "\n",
    "            addItem(item)\n",
    "\n",
    "    g.bind(\"skos\", SKOS)\n",
    "    g.bind(\"dct\", DCTERMS)\n",
    "    g.bind(\"eaf\", base_url)\n",
    "\n",
    "    output = g.serialize(format='turtle', base=base_url).decode(\"utf-8\")\n",
    "\n",
    "    data_path = Path.cwd() / \"data\"\n",
    "    data_path.mkdir(exist_ok=True)\n",
    "    with open(\"data/eaf-graph-by-subject.ttl\", \"w\") as f:\n",
    "        f.write(output)\n",
    "\n",
    "buildGraph(discipline_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TODO check gnd or wikidata for entry ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('outputfile.json') as js_file:\n",
    "    data = json.load(js_file)\n",
    "\n",
    "def buildDisciplineNodes(nodes):\n",
    "    disciplineNodes = set(item[\"discipline\"][\"de\"] for item in data)\n",
    "    return disciplineNodes\n",
    "\n",
    "disciplines = buildDisciplineNodes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"eaf-graph-all.ttl\", \"w\") as f:\n",
    "    f.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/Users/steffenroertgen/gwdg_owncloud/coding/openeduhub/oeh-metadata-eaf-schlagwortverzeichnis/eaf-schlagwortverzeichnis-env/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "eaf-schlagwortverzeichnis-env",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "eaf-schlagwortverzeichnis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "name": "csv_to_skos.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
