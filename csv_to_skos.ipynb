{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import re\n",
    "from rdflib import Namespace, Graph, Literal, URIRef, RDF, SKOS, DCTERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distict disciplines: ('', 'Verkehrserziehung', 'Interkulturelle Bildung', 'Ethik', 'Musik', 'Arbeitslehre', 'Grundschule', 'Gesundheit', 'Fremdsprachen', 'Spiel- und Dokumentarfilm', 'Geschichte', 'Berufliche Bildung', 'Informationstechnische Bildung', 'Pädagogik', 'Politische Bildung', 'Religion', 'Geographie', 'Freizeit', 'Bildende Kunst', 'Biologie', 'Sucht und Prävention', 'Physik', 'Deutsch', 'Chemie', 'Retten, Helfen, Schützen', 'Elementarbereich, Vorschulerziehung', 'Umweltgefährdung, Umweltschutz', 'Wirtschaftskunde', 'Medienpädagogik', 'Leben', 'Sexualerziehung', 'Sport', 'Mathematik')\n",
      "Number of distinct disciplines: 33\n"
     ]
    }
   ],
   "source": [
    "# TODO add notation eaf datatype\n",
    "\n",
    "csv_path = Path.cwd() / \"data\" / \"csv\" / \"schlagworte.csv\"\n",
    "\n",
    "\n",
    "def open_csv(csv_path) -> list:\n",
    "    csv_data = []\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\"|\")\n",
    "        for row in reader:\n",
    "            csv_data.append(row)\n",
    "    return csv_data\n",
    "\n",
    "# Schlagwort: Definierter Begriff, kann aus einem oder mehreren Wörtern bestehen, kann Deskriptor oder Nicht-Desckriptor sein\n",
    "# Art: DS = Deskriptor, ND = Nicht-Deskriptor, (Verweis mit s. im Feld \"Text\"), D = Deskriptor mit Verweis im Feld \"Text\"\n",
    "# Feldbegr: Feldbegriff, Kategorisierung der Deskriptoren\n",
    "# Text: Definition des Deskriptors oder Querverweis mit \"s.\" und \"s.a.\"\n",
    "\n",
    "\n",
    "def findAllNodes(data):\n",
    "    for item in data:\n",
    "        if item[\"ART\"] == \"DS\":\n",
    "            # item is main node append it\n",
    "            node = {\n",
    "                \"schlagwort\": item[\"SCHLAGWORT\"],\n",
    "                \"dokument-id\": item[\"DOKUMENT-ID\"],\n",
    "                \"text\": item[\"TEXT\"],\n",
    "                \"discipline\": item[\"FELDBEGR\"]\n",
    "            }\n",
    "            root.append(node)\n",
    "\n",
    "csv_data = open_csv(csv_path)\n",
    "root = []\n",
    "\n",
    "findAllNodes(csv_data)\n",
    "disciplines = set([node['discipline'] for node in root])\n",
    "print(f\"Distict disciplines: {*disciplines,}\")\n",
    "print(f\"Number of distinct disciplines: {len(disciplines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append all all Nodes to their respective discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildListOfDisciplines(data):\n",
    "    discipline_list = []\n",
    "    for item in data:\n",
    "        # second iteration when all mein node exists\n",
    "        # if item is a Non-Deskriptor find its Deskriptor (DS) and append it to DS as hiddenLabel\n",
    "        try:\n",
    "            if item[\"ART\"] == \"DS\":\n",
    "                discipline = node[\"discipline\"]\n",
    "\n",
    "                # if list empty, append the discipline\n",
    "                if len(discipline_list) == 0:\n",
    "                    discipline_list.append({discipline: []})\n",
    "                # check if the discipline is already there, otherwise append\n",
    "                elif len([d for d in discipline_list if discipline in d.keys()]) == 0:\n",
    "                    discipline_list.append({discipline: []})\n",
    "                \n",
    "                next(d[discipline] for d in discipline_list if discipline in d.keys()).append({\n",
    "                    \"schlagwort\": item[\"SCHLAGWORT\"],\n",
    "                    \"art\": item[\"ART\"],\n",
    "                    \"dokument-id\": item[\"DOKUMENT-ID\"],\n",
    "                    \"text\": item[\"TEXT\"],\n",
    "                    \"discipline\": item[\"FELDBEGR\"]\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                # find the descriptor\n",
    "                descriptor = re.split(descriptor_split, item[\"TEXT\"])[-1].strip()\n",
    "\n",
    "                # find the node it belongs to\n",
    "                node = next(n for n in root if descriptor in n[\"schlagwort\"])\n",
    "                if not node:\n",
    "                    node = next(n for n in root if n[\"schlagwort\"] == descriptor)\n",
    "\n",
    "                discipline = node[\"discipline\"]\n",
    "                \n",
    "                # if list empty, append the discipline\n",
    "                if len(discipline_list) == 0:\n",
    "                    discipline_list.append({discipline: []})\n",
    "                # check if the discipline is already there, otherwise append\n",
    "                elif len([d for d in discipline_list if discipline in d.keys()]) == 0:\n",
    "                    discipline_list.append({discipline: []})\n",
    "                \n",
    "                next(d[discipline] for d in discipline_list if discipline in d.keys()).append({\n",
    "                    \"schlagwort\": item[\"SCHLAGWORT\"],\n",
    "                    \"art\": item[\"ART\"],\n",
    "                    \"dokument-id\": item[\"DOKUMENT-ID\"],\n",
    "                    \"text\": item[\"TEXT\"],\n",
    "                    \"discipline\": item[\"FELDBEGR\"]\n",
    "                    })\n",
    "\n",
    "        except:\n",
    "            print(\n",
    "                f\"did not find root: {descriptor} at item: {item['DOKUMENT-ID']}\")\n",
    "    return discipline_list\n",
    "\n",
    "descriptor_split = re.compile(r\"s\\.a\\.|s\\.\")\n",
    "\n",
    "\n",
    "discipline_list = buildListOfDisciplines(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build csv files for each discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religion has 1809 items\n",
      "Geschichte has 2749 items\n",
      "Geographie has 8440 items\n",
      "Deutsch has 970 items\n",
      "Musik has 1014 items\n",
      "Verkehrserziehung has 803 items\n",
      "Physik has 2215 items\n",
      "Wirtschaftskunde has 1361 items\n",
      "Medienpädagogik has 478 items\n",
      "Ethik has 86 items\n",
      "Leben has 1761 items\n",
      "Politische Bildung has 1434 items\n",
      "Gesundheit has 1979 items\n",
      "Sport has 2675 items\n",
      "Biologie has 6321 items\n",
      "Bildende Kunst has 1663 items\n",
      "Freizeit has 530 items\n",
      "Chemie has 1267 items\n",
      "Mathematik has 576 items\n",
      "Umweltgefährdung, Umweltschutz has 809 items\n",
      "Arbeitslehre has 2055 items\n",
      "Pädagogik has 847 items\n",
      "Spiel- und Dokumentarfilm has 432 items\n",
      "Grundschule has 32 items\n",
      "Informationstechnische Bildung has 841 items\n",
      "Sucht und Prävention has 160 items\n",
      "Berufliche Bildung has 1332 items\n",
      "Fremdsprachen has 606 items\n",
      "Sexualerziehung has 171 items\n",
      "Interkulturelle Bildung has 260 items\n",
      "Retten, Helfen, Schützen has 180 items\n",
      "Elementarbereich, Vorschulerziehung has 41 items\n",
      " has 0 items\n"
     ]
    }
   ],
   "source": [
    "csv_out_path = Path.cwd() / \"data\" / \"csv_out\"\n",
    "csv_out_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for d in discipline_list:\n",
    "    discipline = next(iter(d))\n",
    "    csv_path = Path(csv_out_path / (str(discipline) + \".csv\"))\n",
    "    csv_path.touch(exist_ok=True)\n",
    "    with open(Path(csv_out_path / (str(discipline) + \".csv\")), 'w', newline='') as csvfile:\n",
    "        fieldnames = ['notation', 'prefLabel', 'art', 'definition']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames,extrasaction='ignore')\n",
    "\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for i, item in enumerate(d[discipline]):\n",
    "            writer.writerow(item)\n",
    "        print(f\"{discipline} has {i} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check gnd or wikidata for entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendToRootNodes(data):\n",
    "    for item in data:\n",
    "        # second iteration when all mein node exists\n",
    "        # if item is a Non-Deskriptor find its Deskriptor (DS) and append it to DS as hiddenLabel\n",
    "        try:\n",
    "            if item[\"ART\"] == \"ND\":\n",
    "                # find the descriptor\n",
    "                descriptor = re.split(descriptor_split, item[\"TEXT\"])[-1].strip()\n",
    "\n",
    "                node = next(n for n in root if descriptor in n[\"prefLabel\"][\"de\"])\n",
    "                if not node:\n",
    "                    node = next(n for n in root if n[\"prefLabel\"][\"de\"] == descriptor)\n",
    "\n",
    "                node.setdefault(\"hiddenLabel\", []).append({\"de\": item[\"SCHLAGWORT\"]})\n",
    "\n",
    "            elif item[\"ART\"] == \"D\":\n",
    "                descriptor = re.split(descriptor_split, item[\"TEXT\"])[-1].strip()\n",
    "\n",
    "                node = next(n for n in root if descriptor in n[\"prefLabel\"][\"de\"])\n",
    "                if not node:\n",
    "                    node = next(n for n in root if n[\"prefLabel\"][\"de\"] == descriptor)\n",
    "                node.setdefault(\"altLabel\", []).append({\"de\": item[\"SCHLAGWORT\"]})\n",
    "        except:\n",
    "            print(\n",
    "                f\"did not find root: {descriptor} at item: {item['DOKUMENT-ID']}\")\n",
    "\n",
    "\n",
    "descriptor_split = re.compile(r\"s\\.a\\.|s\\.\")\n",
    "\n",
    "appendToRootNodes(csv_data)\n",
    "\n",
    "with open('outputfile.json', 'w') as fout:\n",
    "    json.dump(root, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('outputfile.json') as js_file:\n",
    "    data = json.load(js_file)\n",
    "\n",
    "def buildDisciplineNodes(nodes):\n",
    "    disciplineNodes = set(item[\"discipline\"][\"de\"] for item in data)\n",
    "    return disciplineNodes\n",
    "\n",
    "disciplines = buildDisciplineNodes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_disciplines = {}\n",
    "for item in data:\n",
    "    root_disciplines.setdefault(item[\"discipline\"][\"de\"], []).append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Geographie', 'Bildende Kunst', 'Religion', 'Biologie', 'Sport', 'Physik', 'Verkehrserziehung', 'Spiel- und Dokumentarfilm', 'Deutsch', 'Grundschule', 'Umweltgefährdung, Umweltschutz', 'Politische Bildung', 'Informationstechnische Bildung', 'Musik', 'Interkulturelle Bildung', 'Geschichte', 'Pädagogik', 'Gesundheit', 'Mathematik', 'Wirtschaftskunde', 'Fremdsprachen', 'Leben', 'Chemie', 'Berufliche Bildung', 'Arbeitslehre', 'Medienpädagogik', 'Sucht und Prävention', 'Ethik', 'Freizeit', 'Elementarbereich, Vorschulerziehung', 'Retten, Helfen, Schützen', 'Sexualerziehung'])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(root_disciplines.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics_name = \"eaf-schlagwortsystematik-all\"\n",
    "g = Graph()\n",
    "namespace = Namespace(\"http://w3id.org/openeduhub/vocabs/\" + systematics_name + \"/\")\n",
    "base_url = URIRef(namespace)\n",
    "\n",
    "g.add(( base_url, RDF.type, SKOS.ConceptScheme))\n",
    "g.add(( base_url, DCTERMS.Title, Literal(systematics_name, lang=\"de\")))\n",
    "\n",
    "\n",
    "for discipline in root_disciplines.keys():\n",
    "    discipline_url = URIRef(namespace + str(discipline.lower().replace(\" \", \"-\")))\n",
    "    g.add( (discipline_url, RDF.type, SKOS.Concept) )\n",
    "    g.add( (discipline_url, SKOS.prefLabel, Literal(str(discipline.lower()), lang=\"de\" ) ) )\n",
    "\n",
    "    # add topConceptOf\n",
    "    g.add(( discipline_url, SKOS.topConceptOf, base_url) )\n",
    "    g.add(( base_url, SKOS.hasTopConcept, discipline_url) )\n",
    "    \n",
    "    for item in root_disciplines[discipline]:\n",
    "        item_url = URIRef(namespace + str(item[\"notation\"][\"de\"].lower().replace(\" \", \"-\")))\n",
    "\n",
    "        # add item to discipline narrower\n",
    "        g.add((discipline_url, SKOS.narrower, item_url))\n",
    "        # and add discipline narrower to item broader\n",
    "        g.add((item_url, SKOS.broader, discipline_url))\n",
    "        \n",
    "        g.add(( item_url, SKOS.inScheme, base_url))\n",
    "        \n",
    "\n",
    "        g.add( (item_url, RDF.type, SKOS.Concept) )\n",
    "        g.add( (item_url, SKOS.prefLabel, Literal(item[\"prefLabel\"][\"de\"], lang=\"de\")) )\n",
    "        \n",
    "        if \"altLabel\" in item:\n",
    "            for label in item[\"altLabel\"]:\n",
    "                g.add( (item_url, SKOS.altLabel, Literal(label[\"de\"], lang=\"de\") ) )\n",
    "        if \"hiddenLabel\" in item:\n",
    "            for label in item[\"hiddenLabel\"]:\n",
    "                g.add( (item_url, SKOS.hiddenLabel, Literal(label[\"de\"], lang=\"de\") ) )\n",
    "\n",
    "g.bind(\"skos\", SKOS)\n",
    "g.bind(\"dct\", DCTERMS)\n",
    "g.bind(\"eaf\", base_url)\n",
    "\n",
    "output = g.serialize(format='turtle', base=base_url).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eaf-graph-all.ttl\", \"w\") as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eaf-schlagwortverzeichnis-env",
   "language": "python",
   "name": "eaf-schlagwortverzeichnis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
